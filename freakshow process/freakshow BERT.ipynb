{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"cleaned_freakshow_training.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sideshow          213\n",
      "politics          193\n",
      "sports            145\n",
      "music             109\n",
      "mass media         87\n",
      "car show           69\n",
      "theatre            29\n",
      "art                19\n",
      "freakshow          13\n",
      "economy            11\n",
      "crime               7\n",
      "tech                3\n",
      "wine                3\n",
      "celebrity           2\n",
      "graphic design      2\n",
      "antiques            1\n",
      "drunkeness          1\n",
      "halloween           1\n",
      "Name: Category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 创建一个函数，用于标准化 Category 列\n",
    "def clean_category(category):\n",
    "    category = category.strip().lower()  # 去除首尾空格并统一小写\n",
    "\n",
    "    # 修正特定类别拼写和大小写不一致\n",
    "    corrections = {\n",
    "        \"car\": \"car show\",\n",
    "        \"car show\": \"car show\",\n",
    "        \"car show*\": \"car show\",\n",
    "        \"carshow\": \"car show\",\n",
    "        \"politics\": \"politics\",\n",
    "        \"mass media\": \"mass media\",\n",
    "        \"sports\": \"sports\",\n",
    "        \"music\": \"music\",\n",
    "        \"freakshow\": \"freakshow\",\n",
    "        \"sideshow\": \"sideshow\",\n",
    "        \"sideshow*\": \"sideshow\",\n",
    "        \"wine\": \"wine\",\n",
    "        \"theater\": \"theatre\",  # 修正美式拼写\n",
    "        \"theatre\": \"theatre\",\n",
    "        \"graphic design\": \"graphic design\",\n",
    "        \"crime\": \"crime\",\n",
    "        \"tech\": \"tech\",\n",
    "        \"economy\": \"economy\",\n",
    "        \"celebrity\": \"celebrity\",\n",
    "        \"drunkeness\": \"drunkeness\",\n",
    "        \"antiques\": \"antiques\"\n",
    "    }\n",
    "\n",
    "    # 返回修正后的类别\n",
    "    return corrections.get(category, category)  # 如果未匹配到 corrections，则保留原类别\n",
    "\n",
    "# 应用清理函数到 Category 列\n",
    "data['Category'] = data['Category'].apply(clean_category)\n",
    "\n",
    "# 检查清理后的类别分布\n",
    "print(data['Category'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered category distribution:\n",
      "sideshow      201\n",
      "politics      183\n",
      "sports        133\n",
      "music         104\n",
      "mass media     83\n",
      "car show       66\n",
      "theatre        28\n",
      "art            17\n",
      "freakshow      12\n",
      "economy        10\n",
      "Name: Category, dtype: int64\n",
      "Original data size: 837, Filtered data size: 837\n"
     ]
    }
   ],
   "source": [
    "\n",
    "category_counts = data['Category'].value_counts()\n",
    "categories_to_remove = category_counts[category_counts < 10].index.tolist()\n",
    "\n",
    "\n",
    "data = data[~data['Category'].isin(categories_to_remove)].reset_index(drop=True)\n",
    "\n",
    "print(\"Filtered category distribution:\")\n",
    "print(data['Category'].value_counts())\n",
    "\n",
    "print(f\"Original data size: {len(data)}, Filtered data size: {len(data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "837"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 908 entries, 0 to 907\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Category         908 non-null    object\n",
      " 1   Date             853 non-null    object\n",
      " 2   URL              908 non-null    object\n",
      " 3   Content          856 non-null    object\n",
      " 4   content_length   908 non-null    int64 \n",
      " 5   cleaned_content  856 non-null    object\n",
      " 6   label_encoded    908 non-null    int64 \n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 49.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping from Category to label_encoded:\n",
      "{'art': 0, 'car show': 1, 'economy': 2, 'freakshow': 3, 'mass media': 4, 'music': 5, 'politics': 6, 'sideshow': 7, 'sports': 8, 'theatre': 9}\n",
      "\n",
      "Encoded label distribution:\n",
      "7    201\n",
      "6    183\n",
      "8    133\n",
      "5    104\n",
      "4     83\n",
      "1     66\n",
      "9     28\n",
      "0     17\n",
      "3     12\n",
      "2     10\n",
      "Name: label_encoded, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# unique encoding\n",
    "category_to_label = {category: idx for idx, category in enumerate(sorted(data['Category'].unique()))}\n",
    "\n",
    "data['label_encoded'] = data['Category'].map(category_to_label)\n",
    "\n",
    "print(\"Mapping from Category to label_encoded:\")\n",
    "print(category_to_label)\n",
    "\n",
    "print(\"\\nEncoded label distribution:\")\n",
    "print(data['label_encoded'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'cleaned_content' miss value：0\n",
      "'label_encoded' miss value：0\n"
     ]
    }
   ],
   "source": [
    "# check cleaned_content ,label_encoded miss value\n",
    "missing_cleaned_content = data['cleaned_content'].isnull().sum()\n",
    "missing_label_encoded = data['label_encoded'].isnull().sum()\n",
    "\n",
    "print(f\"'cleaned_content' miss value：{missing_cleaned_content}\")\n",
    "print(f\"'label_encoded' miss value：{missing_label_encoded}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "837\n"
     ]
    }
   ],
   "source": [
    "data = data.dropna(subset=['cleaned_content']).reset_index(drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    8.370000e+02\n",
      "mean     5.200495e+03\n",
      "std      5.926315e+04\n",
      "min      5.000000e+00\n",
      "25%      1.047000e+03\n",
      "50%      2.157000e+03\n",
      "75%      3.543000e+03\n",
      "max      1.708178e+06\n",
      "Name: content_length, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data['content_length'] = data['cleaned_content'].apply(len)\n",
    "\n",
    "print(data['content_length'].describe())\n",
    "\n",
    "# length distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(data['content_length'], bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Text Lengths')\n",
    "plt.xlabel('Text Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input_ids: torch.Size([837, 512])\n",
      "Shape of attention_mask: torch.Size([837, 512])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Define a function to tokenize text data with truncation and padding\n",
    "def tokenize_data(texts, tokenizer, max_length=512):\n",
    "    \"\"\"\n",
    "    Tokenize input text data using BERT tokenizer.\n",
    "    Parameters:\n",
    "        texts (list of str): List of text data to tokenize.\n",
    "        tokenizer (BertTokenizer): Pre-trained BERT tokenizer.\n",
    "        max_length (int): Maximum sequence length for padding/truncation.\n",
    "    Returns:\n",
    "        dict: Dictionary with tokenized input_ids, attention_mask.\n",
    "    \"\"\"\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        truncation=True,         # Truncate sequences to max_length\n",
    "        padding=\"max_length\",    # Pad sequences to max_length\n",
    "        max_length=max_length,   # Maximum sequence length\n",
    "        return_tensors=\"pt\"      # Return PyTorch tensors\n",
    "    )\n",
    "\n",
    "# Tokenize the text data (cleaned_content column)\n",
    "max_length = 512  # Define the fixed sequence length\n",
    "encodings = tokenize_data(data['cleaned_content'].tolist(), tokenizer, max_length=max_length)\n",
    "\n",
    "# Check the shape of tokenized inputs\n",
    "print(f\"Shape of input_ids: {encodings['input_ids'].shape}\")        # Shape of token IDs\n",
    "print(f\"Shape of attention_mask: {encodings['attention_mask'].shape}\")  # Shape of attention mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the dataset: 837\n",
      "Example of a dataset sample:\n",
      "{'input_ids': tensor([  101, 22042,  3696,  5993,  2744,  4650,  3191,  9394,  3343,  3696,\n",
      "         1999,  6279,  2591,  4070,  2180,  2102,  2695,  4070, 20786,  2442,\n",
      "         2421,  3696,  1999,  6279,  2591,  4070,  2180,  2102,  2695,  4070,\n",
      "        20786,  2442,  2421,  2064,  2102,  2767,  2208,  5045,  2067, 28997,\n",
      "         4971,  2047,  2299, 20739,  2491,  2028,  2154,  4971,  3333,  4487,\n",
      "         2015,  2650,  6136,  2402,  5003,  1051,  9541,  2226,  2226,  2226,\n",
      "         6160,  2225,  7110,  2102,  2166, 11623,  2994, 12065,  2102,  2175,\n",
      "         2078,  2707,  2514,  2066,  3190,  2562,  4172,  2072, 19808,  3501,\n",
      "         3903, 14406,  2208,  9680, 20739,  2491,  2207,  9857,  2244, 18592,\n",
      "         3128,  4431,  4971, 11155, 13552,  7867, 15969,  4679,  7867,  6884,\n",
      "         5745, 15994,  9680,  4691,  5598, 15969,  4679,  2123,  2102, 15121,\n",
      "         2051,  2175,  2852, 10993,  9096,  2123,  2102,  9680,  3198,  7743,\n",
      "         2113, 10506,  2480,  8132, 10657,  2693,  2474,  2404,  1038,  2067,\n",
      "         2208,  2036,  2507, 27863, 11245,  5833, 14068,  2666,  9033, 12439,\n",
      "         3728,  3662,  2490,  4971, 13463,  5490,  6692, 11362,  2202, 14068,\n",
      "         2067, 24497, 16021, 23091,  2559,  2066,  2388, 24316,  2075, 14068,\n",
      "        16078,  2208,  9680,  5147,  4942, 29234,  2094,  6608,  5993,  2744,\n",
      "         9394,  3343,  4374, 10373,  1057,  4882,  4638,  6745,  2739,  8224,\n",
      "         2739,  4638,  6745,  2739,  6207,  2739,  2064,  2102,  2562,  2067,\n",
      "         5685, 15628, 13552,  2182,  1056,  6392,  2099,  2544, 12486,  2211,\n",
      "         3041,  3204,  2208,  3555,  4971,  5496,  2920,  5977,  9803,  2238,\n",
      "        11912, 13742,  4971,  3202,  6380,  2035, 29107,  3508, 15870,  2713,\n",
      "         2093,  4487,  2015,  2650, 10320,  3507, 10687,  2804,  8618,  2420,\n",
      "        10052, 16021, 23091, 13552,  4952,  2208, 20739,  2491,  5147,  4942,\n",
      "        29234,  2094,  6608,  5993,  2744,  9394,  3343,  4374, 10373,  1057,\n",
      "         4882,  5147,  4942, 29234,  2094,  6608,  5993,  2744,  9394,  3343,\n",
      "         4374, 10373,  1057,  4882,  1057,  4882,  8727,  5386,  2089,  4374,\n",
      "         9430,  4957,  4031,  2326,  5147,  4942, 29234,  2094,  6608,  5993,\n",
      "         2744,  9394,  3343,  4374, 10373,  1057,  4882,  1057,  4882,  2112,\n",
      "         2112,  2572,  2098,  2401,  4024,  2177,  2572,  2098,  2401,  6113,\n",
      "         2773, 20110, 21722,   102,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(5)}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextClassificationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset for text classification.\n",
    "    This class combines tokenized inputs and labels.\n",
    "    \"\"\"\n",
    "    def __init__(self, encodings, labels):\n",
    "        \"\"\"\n",
    "        Initialize the dataset with tokenized inputs and labels.\n",
    "        Parameters:\n",
    "            encodings (dict): Tokenized input data (input_ids and attention_mask).\n",
    "            labels (list or torch.Tensor): Corresponding labels for the data.\n",
    "        \"\"\"\n",
    "        self.encodings = encodings\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)  # Convert labels to tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the total number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieve a single sample from the dataset.\n",
    "        Parameters:\n",
    "            idx (int): Index of the sample to retrieve.\n",
    "        Returns:\n",
    "            dict: A dictionary containing input_ids, attention_mask, and labels.\n",
    "        \"\"\"\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}  # input_ids and attention_mask\n",
    "        item['labels'] = self.labels[idx]  # Add the label\n",
    "        return item\n",
    "\n",
    "# Prepare labels\n",
    "labels = data['label_encoded'].tolist()  # Extract labels as a list\n",
    "\n",
    "# Create dataset instance\n",
    "dataset = TextClassificationDataset(encodings, labels)\n",
    "\n",
    "# Check the dataset\n",
    "print(f\"Number of samples in the dataset: {len(dataset)}\")\n",
    "print(\"Example of a dataset sample:\")\n",
    "print(dataset[0])  # Display the first sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 669\n",
      "Number of validation samples: 168\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "train_size = 0.8  # Proportion of data used for training\n",
    "train_indices, val_indices = train_test_split(\n",
    "    list(range(len(dataset))), \n",
    "    test_size=1 - train_size, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Subset the dataset for training and validation\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "\n",
    "# Define DataLoaders for training and validation\n",
    "batch_size = 16  # Define batch size\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Check the size of each set\n",
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of validation samples: {len(val_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_labels are 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded and moved to device: cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "# Define the number of classes (unique labels in the dataset)\n",
    "num_labels = len(data['label_encoded'].unique())+1\n",
    "print(\"num_labels are\", num_labels)\n",
    "# Load pre-trained BERT model with a classification head\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",    # Pre-trained BERT model\n",
    "    num_labels=num_labels   # Number of output classes\n",
    ")\n",
    "\n",
    "# Move the model to the appropriate device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Model loaded and moved to device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer, loss function, and scheduler initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a123/anaconda3/lib/python3.11/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Define loss function (for classification tasks)\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "# Optionally, define a learning rate scheduler\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.1)  # Decays learning rate every 2 epochs\n",
    "\n",
    "print(\"Optimizer, loss function, and scheduler initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Define the training loop\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch.\n",
    "    Parameters:\n",
    "        model (torch.nn.Module): BERT model with classification head.\n",
    "        data_loader (DataLoader): DataLoader for training data.\n",
    "        loss_fn (function): Loss function (e.g., CrossEntropyLoss).\n",
    "        optimizer (torch.optim.Optimizer): Optimizer (e.g., AdamW).\n",
    "        device (torch.device): Device to run the training on (CPU or GPU).\n",
    "    Returns:\n",
    "        float: Average loss over the epoch.\n",
    "    \"\"\"\n",
    "    model.train()  # Set model to training mode\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(data_loader, desc=\"Training\"):\n",
    "        optimizer.zero_grad()  # Clear gradients from the previous step\n",
    "\n",
    "        # Move batch data to the target device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Return average loss\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "\n",
    "# Define the validation loop\n",
    "def eval_model(model, data_loader, loss_fn, device):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the validation set.\n",
    "    Parameters:\n",
    "        model (torch.nn.Module): BERT model with classification head.\n",
    "        data_loader (DataLoader): DataLoader for validation data.\n",
    "        loss_fn (function): Loss function (e.g., CrossEntropyLoss).\n",
    "        device (torch.device): Device to run the evaluation on (CPU or GPU).\n",
    "    Returns:\n",
    "        tuple: (average loss, accuracy)\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            # Move batch data to the target device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Compute accuracy\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct_predictions += (preds == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    # Compute average loss and accuracy\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 42/42 [12:57<00:00, 18.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.0545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 11/11 [00:40<00:00,  3.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 1.7221\n",
      "Validation accuracy: 0.4940\n",
      "\n",
      "Epoch 2/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 1/42 [00:16<11:19, 16.58s/it]"
     ]
    }
   ],
   "source": [
    "# Define the number of training epochs\n",
    "num_epochs = 7  # You can adjust based on your dataset and task\n",
    "\n",
    "# Track training progress\n",
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_accuracy\": []\n",
    "}\n",
    "\n",
    "# Main training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # Train the model for one epoch\n",
    "    train_loss = train_epoch(model, train_loader, loss_fn, optimizer, device)\n",
    "    print(f\"Training loss: {train_loss:.4f}\")\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    val_loss, val_accuracy = eval_model(model, val_loader, loss_fn, device)\n",
    "    print(f\"Validation loss: {val_loss:.4f}\")\n",
    "    print(f\"Validation accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Save metrics for plotting or analysis\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"val_loss\"].append(val_loss)\n",
    "    history[\"val_accuracy\"].append(val_accuracy)\n",
    "\n",
    "    # Update learning rate (if using a scheduler)\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "# Print summary of training\n",
    "print(\"\\nTraining complete!\")\n",
    "print(f\"Best validation accuracy: {max(history['val_accuracy']):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test samples: 257\n"
     ]
    }
   ],
   "source": [
    "# Split off a test set if not already done\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "_, test_indices = train_test_split(list(range(len(dataset))), test_size=0.3, random_state=42)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Number of test samples: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate the model on a given dataset.\n",
    "    Parameters:\n",
    "        model (torch.nn.Module): Trained model to evaluate.\n",
    "        data_loader (DataLoader): DataLoader for the evaluation dataset.\n",
    "        device (torch.device): Device to perform evaluation on.\n",
    "    Returns:\n",
    "        dict: Evaluation metrics including accuracy and classification report.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for batch in data_loader:\n",
    "            # Move batch data to the target device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Store predictions and true labels\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            predictions.extend(preds)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Compute evaluation metrics\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    report = classification_report(true_labels, predictions, output_dict=True)\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"classification_report\": report}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7899\n",
      "\n",
      "Classification Report:\n",
      "{'1': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 6},\n",
      " '10': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
      " '12': {'f1-score': 0.8181818181818182,\n",
      "        'precision': 0.84375,\n",
      "        'recall': 0.7941176470588235,\n",
      "        'support': 34},\n",
      " '13': {'f1-score': 0.8571428571428572,\n",
      "        'precision': 0.8888888888888888,\n",
      "        'recall': 0.8275862068965517,\n",
      "        'support': 29},\n",
      " '14': {'f1-score': 0.8695652173913043,\n",
      "        'precision': 0.8163265306122449,\n",
      "        'recall': 0.9302325581395349,\n",
      "        'support': 43},\n",
      " '15': {'f1-score': 0.802721088435374,\n",
      "        'precision': 0.7195121951219512,\n",
      "        'recall': 0.9076923076923077,\n",
      "        'support': 65},\n",
      " '17': {'f1-score': 0.9295774647887325,\n",
      "        'precision': 0.8918918918918919,\n",
      "        'recall': 0.9705882352941176,\n",
      "        'support': 34},\n",
      " '20': {'f1-score': 0.6666666666666667,\n",
      "        'precision': 0.8333333333333334,\n",
      "        'recall': 0.5555555555555556,\n",
      "        'support': 9},\n",
      " '21': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 2},\n",
      " '22': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
      " '23': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
      " '25': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
      " '3': {'f1-score': 0.7692307692307693,\n",
      "       'precision': 0.625,\n",
      "       'recall': 1.0,\n",
      "       'support': 15},\n",
      " '4': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 5},\n",
      " '5': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 2},\n",
      " '6': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
      " '7': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 1},\n",
      " '8': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 3},\n",
      " '9': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 4},\n",
      " 'accuracy': 0.7898832684824902,\n",
      " 'macro avg': {'f1-score': 0.3006887306230275,\n",
      "               'precision': 0.29572120209727953,\n",
      "               'recall': 0.3150406584545732,\n",
      "               'support': 257},\n",
      " 'weighted avg': {'f1-score': 0.7446988136682043,\n",
      "                  'precision': 0.714143718293212,\n",
      "                  'recall': 0.7898832684824902,\n",
      "                  'support': 257}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a123/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/a123/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/a123/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "results = evaluate_model(model, test_loader, device)\n",
    "\n",
    "# Print accuracy\n",
    "print(f\"Test Accuracy: {results['accuracy']:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "from pprint import pprint\n",
    "print(\"\\nClassification Report:\")\n",
    "pprint(results['classification_report'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Custom Environment",
   "language": "python",
   "name": "your_environment_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
